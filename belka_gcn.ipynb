{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rdkit\n!pip install duckdb\n!pip install pandas networkx\n!pip install torch\n!pip install torch-geometric\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport duckdb\nfrom torch.utils.data import Dataset\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T09:24:41.874294Z","iopub.execute_input":"2024-06-09T09:24:41.874682Z","iopub.status.idle":"2024-06-09T09:25:55.202661Z","shell.execute_reply.started":"2024-06-09T09:24:41.874652Z","shell.execute_reply":"2024-06-09T09:25:55.201343Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\nDownloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.9.6\nCollecting duckdb\n  Downloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (762 bytes)\nDownloading duckdb-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: duckdb\nSuccessfully installed duckdb-1.0.0\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCollecting torch-geometric\n  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2024.3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\nDownloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.5.3\n/kaggle/input/leash-BELKA/sample_submission.csv\n/kaggle/input/leash-BELKA/train.parquet\n/kaggle/input/leash-BELKA/test.parquet\n/kaggle/input/leash-BELKA/train.csv\n/kaggle/input/leash-BELKA/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/leash-BELKA/train.parquet'\ntest_path = '/kaggle/input/leash-BELKA/test.parquet'\n\ncon = duckdb.connect()\n\ndf = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 30000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 30000)\"\"\").df()\n\ncon.close()\n\ndf = df.drop(['buildingblock1_smiles', 'buildingblock2_smiles', 'buildingblock3_smiles'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:25:55.204888Z","iopub.execute_input":"2024-06-09T09:25:55.205391Z","iopub.status.idle":"2024-06-09T09:26:49.998759Z","shell.execute_reply.started":"2024-06-09T09:25:55.205352Z","shell.execute_reply":"2024-06-09T09:26:49.997488Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f085a640b6442fe86ac83db4f216112"}},"metadata":{}}]},{"cell_type":"code","source":"df.sample(n=20)\n# print(df)\n# rows, col= smiles_df.shape\n# print(f\"Number of rows: {rows}, Number of rows: {col}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:26:50.000348Z","iopub.execute_input":"2024-06-09T09:26:50.000848Z","iopub.status.idle":"2024-06-09T09:26:50.027311Z","shell.execute_reply.started":"2024-06-09T09:26:50.000808Z","shell.execute_reply":"2024-06-09T09:26:50.025993Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              id                                    molecule_smiles  \\\n55726   72811836  COC(=O)c1sc(-c2ccc(Cl)cc2)cc1Nc1nc(Nc2ccc(F)c(...   \n33921   81827666  CCOCCCNc1nc(NCC2CCC(C(=O)N[Dy])CC2)nc(Nc2ccc(N...   \n12228  289020876  CS(=O)(=O)Nc1ccc(-c2csc(Nc3nc(NCC4CC5(CC5)CO4)...   \n32929  177373345  Cc1cccc2sc(Nc3nc(Nc4cc(I)ccc4C(=O)N[Dy])nc(Nc4...   \n47126   33338641  COc1cc(Nc2nc(NCc3cnc4n3CCOC4)nc(Nc3cc(F)c(F)cc...   \n58247  287088935  Cc1cc2cc(CNc3nc(NCC45CC6CC(CC(C6)C4)C5)nc(N4c5...   \n13742  120246176  COC(=O)c1scnc1Nc1nc(NCCC(=O)Nc2ncccc2C)nc(N[C@...   \n14474  106147583  O=C1CN(CCCNc2nc(NCCCN3CCNC(=O)C3)nc(N[C@@H](Cc...   \n53063  218163789  COc1ccc(Nc2nc(Nc3ccnc(C(=O)N[Dy])c3)nc(Nc3cc(C...   \n47998   86592738  COc1ccccc1-c1nnc(Nc2nc(Nc3ccc(=O)n(C)c3)nc(N[C...   \n5592   132911703  C#CCOc1cccc(CNc2nc(NCc3ccc4[nH]ccc4c3)nc(Nc3c(...   \n7053    34993906  CCSCCNc1nc(NCC2(C)CCC3(CC2)OCCO3)nc(N[C@@H](Cc...   \n39261   55352303  COC(=O)c1ccsc1Nc1nc(Nc2cc(C(=O)N[Dy])ccc2C)nc(...   \n9233   255125375  COC(=O)c1cccc(Nc2nc(Nc3nc4c(Br)cccc4s3)nc(N[C@...   \n25139   27557791  COC(=O)c1ccc(C(=O)N[Dy])c(Nc2nc(NCCSSC)nc(Nc3n...   \n21294  220232629  CN1CCN(Cc2ccc(Nc3nc(Nc4ccc([N+](=O)[O-])c(Br)c...   \n56534   60431003  Cc1cccc(Nc2nc(NCc3cncc(F)c3)nc(Nc3cncnc3)n2)c1...   \n52585   82668518  CC(=O)c1ccc(Nc2nc(NCC3CCC(C(=O)N[Dy])CC3)nc(Nc...   \n34504   82133486  CSCc1nnc(CNc2nc(NCC3CCC(C(=O)N[Dy])CC3)nc(Nc3c...   \n7911    25894008  CN(c1nc(NCc2cnn(Cc3ccccc3)c2)nc(Nc2nccs2)n1)[C...   \n\n      protein_name  binds  \n55726         BRD4      1  \n33921          sEH      1  \n12228         BRD4      0  \n32929          HSA      1  \n47126          HSA      1  \n58247          sEH      1  \n13742          sEH      0  \n14474          sEH      0  \n53063         BRD4      1  \n47998         BRD4      1  \n5592          BRD4      0  \n7053           HSA      0  \n39261          sEH      1  \n9233           sEH      0  \n25139          HSA      0  \n21294          HSA      0  \n56534          sEH      1  \n52585          sEH      1  \n34504          sEH      1  \n7911          BRD4      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>molecule_smiles</th>\n      <th>protein_name</th>\n      <th>binds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55726</th>\n      <td>72811836</td>\n      <td>COC(=O)c1sc(-c2ccc(Cl)cc2)cc1Nc1nc(Nc2ccc(F)c(...</td>\n      <td>BRD4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33921</th>\n      <td>81827666</td>\n      <td>CCOCCCNc1nc(NCC2CCC(C(=O)N[Dy])CC2)nc(Nc2ccc(N...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12228</th>\n      <td>289020876</td>\n      <td>CS(=O)(=O)Nc1ccc(-c2csc(Nc3nc(NCC4CC5(CC5)CO4)...</td>\n      <td>BRD4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32929</th>\n      <td>177373345</td>\n      <td>Cc1cccc2sc(Nc3nc(Nc4cc(I)ccc4C(=O)N[Dy])nc(Nc4...</td>\n      <td>HSA</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47126</th>\n      <td>33338641</td>\n      <td>COc1cc(Nc2nc(NCc3cnc4n3CCOC4)nc(Nc3cc(F)c(F)cc...</td>\n      <td>HSA</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>58247</th>\n      <td>287088935</td>\n      <td>Cc1cc2cc(CNc3nc(NCC45CC6CC(CC(C6)C4)C5)nc(N4c5...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13742</th>\n      <td>120246176</td>\n      <td>COC(=O)c1scnc1Nc1nc(NCCC(=O)Nc2ncccc2C)nc(N[C@...</td>\n      <td>sEH</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14474</th>\n      <td>106147583</td>\n      <td>O=C1CN(CCCNc2nc(NCCCN3CCNC(=O)C3)nc(N[C@@H](Cc...</td>\n      <td>sEH</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>53063</th>\n      <td>218163789</td>\n      <td>COc1ccc(Nc2nc(Nc3ccnc(C(=O)N[Dy])c3)nc(Nc3cc(C...</td>\n      <td>BRD4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47998</th>\n      <td>86592738</td>\n      <td>COc1ccccc1-c1nnc(Nc2nc(Nc3ccc(=O)n(C)c3)nc(N[C...</td>\n      <td>BRD4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5592</th>\n      <td>132911703</td>\n      <td>C#CCOc1cccc(CNc2nc(NCc3ccc4[nH]ccc4c3)nc(Nc3c(...</td>\n      <td>BRD4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7053</th>\n      <td>34993906</td>\n      <td>CCSCCNc1nc(NCC2(C)CCC3(CC2)OCCO3)nc(N[C@@H](Cc...</td>\n      <td>HSA</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39261</th>\n      <td>55352303</td>\n      <td>COC(=O)c1ccsc1Nc1nc(Nc2cc(C(=O)N[Dy])ccc2C)nc(...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9233</th>\n      <td>255125375</td>\n      <td>COC(=O)c1cccc(Nc2nc(Nc3nc4c(Br)cccc4s3)nc(N[C@...</td>\n      <td>sEH</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25139</th>\n      <td>27557791</td>\n      <td>COC(=O)c1ccc(C(=O)N[Dy])c(Nc2nc(NCCSSC)nc(Nc3n...</td>\n      <td>HSA</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21294</th>\n      <td>220232629</td>\n      <td>CN1CCN(Cc2ccc(Nc3nc(Nc4ccc([N+](=O)[O-])c(Br)c...</td>\n      <td>HSA</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56534</th>\n      <td>60431003</td>\n      <td>Cc1cccc(Nc2nc(NCc3cncc(F)c3)nc(Nc3cncnc3)n2)c1...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>52585</th>\n      <td>82668518</td>\n      <td>CC(=O)c1ccc(Nc2nc(NCC3CCC(C(=O)N[Dy])CC3)nc(Nc...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34504</th>\n      <td>82133486</td>\n      <td>CSCc1nnc(CNc2nc(NCC3CCC(C(=O)N[Dy])CC3)nc(Nc3c...</td>\n      <td>sEH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7911</th>\n      <td>25894008</td>\n      <td>CN(c1nc(NCc2cnn(Cc3ccccc3)c2)nc(Nc2nccs2)n1)[C...</td>\n      <td>BRD4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport torch\nfrom torch_geometric.data import Data\n\ndef smiles_to_graph(smiles, protein_encoding):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None\n\n    AllChem.Compute2DCoords(mol)\n    num_atoms = mol.GetNumAtoms()\n\n    # Node features\n    atom_features = []\n    for atom in mol.GetAtoms():\n        atom_features.append(atom.GetAtomicNum())\n    atom_features = torch.tensor(atom_features, dtype=torch.float).view(-1, 1)\n\n    # Edge indices\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.append((i, j))\n        edge_indices.append((j, i))\n    edge_indices = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n\n    # Protein encoding\n    protein_features = torch.tensor(protein_encoding, dtype=torch.float)\n\n    return Data(x=atom_features, edge_index=edge_indices, protein=protein_features)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:26:50.028739Z","iopub.execute_input":"2024-06-09T09:26:50.029142Z","iopub.status.idle":"2024-06-09T09:26:53.761207Z","shell.execute_reply.started":"2024-06-09T09:26:50.029106Z","shell.execute_reply":"2024-06-09T09:26:53.759839Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse_output=False)\nprotein_encoded = encoder.fit_transform(df[['protein_name']])\ndf['protein_encoded'] = list(protein_encoded)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:26:53.763972Z","iopub.execute_input":"2024-06-09T09:26:53.764639Z","iopub.status.idle":"2024-06-09T09:26:54.184865Z","shell.execute_reply.started":"2024-06-09T09:26:53.764603Z","shell.execute_reply":"2024-06-09T09:26:54.183755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"graph_data_list = []\nfor index, row in df.iterrows():\n    graph = smiles_to_graph(row['molecule_smiles'], row['protein_encoded'])\n    if graph is not None:\n        graph.y = torch.tensor([row['binds']], dtype=torch.float)\n        graph_data_list.append(graph)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:26:54.186874Z","iopub.execute_input":"2024-06-09T09:26:54.187326Z","iopub.status.idle":"2024-06-09T09:29:11.042176Z","shell.execute_reply.started":"2024-06-09T09:26:54.187285Z","shell.execute_reply":"2024-06-09T09:29:11.040889Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def normalize_features(features):\n    mean = features.mean(dim=0, keepdim=True)\n    std = features.std(dim=0, keepdim=True)\n    return (features - mean) / (std + 1e-6)\n\nfor data in graph_data_list:\n    data.x = normalize_features(data.x)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:29:11.044064Z","iopub.execute_input":"2024-06-09T09:29:11.044460Z","iopub.status.idle":"2024-06-09T09:29:14.790893Z","shell.execute_reply.started":"2024-06-09T09:29:11.044427Z","shell.execute_reply":"2024-06-09T09:29:14.789449Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch_geometric.loader import DataLoader\n\nclass MoleculeDataset(Dataset):\n    def __init__(self, data_list):\n        self.data_list = data_list\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def __getitem__(self, idx):\n        return self.data_list[idx]\n\ndataset = MoleculeDataset(graph_data_list)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:29:14.935227Z","iopub.execute_input":"2024-06-09T09:29:14.935807Z","iopub.status.idle":"2024-06-09T09:29:14.956606Z","shell.execute_reply.started":"2024-06-09T09:29:14.935767Z","shell.execute_reply":"2024-06-09T09:29:14.955091Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch.nn import BatchNorm1d\n\nclass GCNWithProtein(torch.nn.Module):\n    def __init__(self, protein_dim):\n        super(GCNWithProtein, self).__init__()\n        self.conv1 = GCNConv(1, 128)\n        self.conv2 = GCNConv(128, 128)\n        self.conv3 = GCNConv(128, 128)\n        self.bn1 = BatchNorm1d(128)\n        self.bn2 = BatchNorm1d(128)\n        self.bn3 = BatchNorm1d(128)\n        self.fc1 = torch.nn.Linear(128 + protein_dim, 256)\n        self.fc2 = torch.nn.Linear(256, 1)\n        self.dropout = torch.nn.Dropout(p=0.3)\n        \n        # Initialize the weights of the linear layers\n        self.init_weights()\n\n    def init_weights(self):\n        torch.nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n        torch.nn.init.kaiming_normal_(self.fc2.weight)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        protein = data.protein\n\n        x = self.conv1(x, edge_index)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        x = self.bn2(x)\n        x = F.relu(x)\n        x = self.conv3(x, edge_index)\n        x = self.bn3(x)\n        x = F.relu(x)\n        x = global_mean_pool(x, batch)\n\n        protein = protein.view(batch.max().item() + 1, -1)\n\n        x = torch.cat([x, protein], dim=1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Get the protein dimension from one-hot encoding\nprotein_dim = len(encoder.categories_[0])\nmodel = GCNWithProtein(protein_dim)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:32:19.102543Z","iopub.execute_input":"2024-06-09T09:32:19.103768Z","iopub.status.idle":"2024-06-09T09:32:19.124911Z","shell.execute_reply.started":"2024-06-09T09:32:19.103711Z","shell.execute_reply":"2024-06-09T09:32:19.123507Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\ncriterion = torch.nn.BCEWithLogitsLoss()\n\ndef train():\n    model.train()\n    for data in train_loader:\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, data.y.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n\ndef evaluate():\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for data in val_loader:\n            output = model(data)\n            loss = criterion(output, data.y.view(-1, 1))\n            val_loss += loss.item()\n    return val_loss / len(val_loader)\n\nfor epoch in range(200):\n    train()\n    val_loss = evaluate()\n    print(f'Epoch {epoch+1}, Validation Loss: {val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:32:21.763765Z","iopub.execute_input":"2024-06-09T09:32:21.764221Z","iopub.status.idle":"2024-06-09T11:28:27.361515Z","shell.execute_reply.started":"2024-06-09T09:32:21.764187Z","shell.execute_reply":"2024-06-09T11:28:27.360260Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1, Validation Loss: 0.6773141724268595\nEpoch 2, Validation Loss: 0.6732469096183776\nEpoch 3, Validation Loss: 0.6706325120925903\nEpoch 4, Validation Loss: 0.6716855664253235\nEpoch 5, Validation Loss: 0.6737308254241944\nEpoch 6, Validation Loss: 0.6699365401268005\nEpoch 7, Validation Loss: 0.6690623424847921\nEpoch 8, Validation Loss: 0.6664311855634053\nEpoch 9, Validation Loss: 0.6635685540835062\nEpoch 10, Validation Loss: 0.6635009922981262\nEpoch 11, Validation Loss: 0.6614815940856934\nEpoch 12, Validation Loss: 0.6596655955314636\nEpoch 13, Validation Loss: 0.6603262114524842\nEpoch 14, Validation Loss: 0.6584972918828328\nEpoch 15, Validation Loss: 0.6629143527348836\nEpoch 16, Validation Loss: 0.6560667153994242\nEpoch 17, Validation Loss: 0.658923126856486\nEpoch 18, Validation Loss: 0.660286503314972\nEpoch 19, Validation Loss: 0.6555044668515523\nEpoch 20, Validation Loss: 0.6622659699122111\nEpoch 21, Validation Loss: 0.6531050465901693\nEpoch 22, Validation Loss: 0.6551520410378774\nEpoch 23, Validation Loss: 0.6501299118995667\nEpoch 24, Validation Loss: 0.6474738168716431\nEpoch 25, Validation Loss: 0.6459133801460266\nEpoch 26, Validation Loss: 0.6473768089612325\nEpoch 27, Validation Loss: 0.6439187474250794\nEpoch 28, Validation Loss: 0.6523813942273458\nEpoch 29, Validation Loss: 0.6454771059354146\nEpoch 30, Validation Loss: 0.6452770668665568\nEpoch 31, Validation Loss: 0.6488410369555155\nEpoch 32, Validation Loss: 0.6419266848564148\nEpoch 33, Validation Loss: 0.6629051642417908\nEpoch 34, Validation Loss: 0.6439531467755636\nEpoch 35, Validation Loss: 0.6515658464431763\nEpoch 36, Validation Loss: 0.6416285521189372\nEpoch 37, Validation Loss: 0.6486912329991659\nEpoch 38, Validation Loss: 0.6723135606447855\nEpoch 39, Validation Loss: 0.6340235582987468\nEpoch 40, Validation Loss: 0.639107828537623\nEpoch 41, Validation Loss: 0.6360189270973206\nEpoch 42, Validation Loss: 0.6512995028495788\nEpoch 43, Validation Loss: 0.6391874237060546\nEpoch 44, Validation Loss: 0.6416047794818878\nEpoch 45, Validation Loss: 0.6423888284365337\nEpoch 46, Validation Loss: 0.6625244824886322\nEpoch 47, Validation Loss: 0.6373549551963806\nEpoch 48, Validation Loss: 0.6509594697157542\nEpoch 49, Validation Loss: 0.618702019850413\nEpoch 50, Validation Loss: 0.6273485818703969\nEpoch 51, Validation Loss: 0.6487641785939534\nEpoch 52, Validation Loss: 0.8751067002614339\nEpoch 53, Validation Loss: 0.6282444567680359\nEpoch 54, Validation Loss: 0.6577135450045267\nEpoch 55, Validation Loss: 0.6226259796619416\nEpoch 56, Validation Loss: 0.6357153430779775\nEpoch 57, Validation Loss: 0.6205896786053975\nEpoch 58, Validation Loss: 0.6337784924507142\nEpoch 59, Validation Loss: 0.6133400708039601\nEpoch 60, Validation Loss: 0.7003705337047577\nEpoch 61, Validation Loss: 0.6090972877343496\nEpoch 62, Validation Loss: 0.6527930064996084\nEpoch 63, Validation Loss: 0.605497887690862\nEpoch 64, Validation Loss: 0.6268501405715943\nEpoch 65, Validation Loss: 0.6826909623940786\nEpoch 66, Validation Loss: 0.7380040587584178\nEpoch 67, Validation Loss: 0.7010271425247192\nEpoch 68, Validation Loss: 0.5975214730898539\nEpoch 69, Validation Loss: 0.6671022073427836\nEpoch 70, Validation Loss: 0.6049397803147634\nEpoch 71, Validation Loss: 0.6110069052378336\nEpoch 72, Validation Loss: 0.5972194852828979\nEpoch 73, Validation Loss: 0.7470167678991954\nEpoch 74, Validation Loss: 0.6780347955226899\nEpoch 75, Validation Loss: 0.6794375495910645\nEpoch 76, Validation Loss: 0.6004880402882894\nEpoch 77, Validation Loss: 0.822935645421346\nEpoch 78, Validation Loss: 0.5932134362061818\nEpoch 79, Validation Loss: 0.6982739085356394\nEpoch 80, Validation Loss: 1.1069483726819356\nEpoch 81, Validation Loss: 0.6098295891284943\nEpoch 82, Validation Loss: 0.6317233250935872\nEpoch 83, Validation Loss: 0.5875097379684449\nEpoch 84, Validation Loss: 0.6270267803668976\nEpoch 85, Validation Loss: 0.8478585180441538\nEpoch 86, Validation Loss: 0.614220173517863\nEpoch 87, Validation Loss: 0.9653362393379211\nEpoch 88, Validation Loss: 0.5902605015436808\nEpoch 89, Validation Loss: 0.6407740965684255\nEpoch 90, Validation Loss: 0.6430399930477142\nEpoch 91, Validation Loss: 0.5875735847949982\nEpoch 92, Validation Loss: 0.6860683573881785\nEpoch 93, Validation Loss: 0.5907679034074148\nEpoch 94, Validation Loss: 0.6258189663887024\nEpoch 95, Validation Loss: 0.6406131342252096\nEpoch 96, Validation Loss: 0.678007869720459\nEpoch 97, Validation Loss: 0.9041563377380372\nEpoch 98, Validation Loss: 0.7923504110972086\nEpoch 99, Validation Loss: 0.8446010658740998\nEpoch 100, Validation Loss: 0.714632617632548\nEpoch 101, Validation Loss: 0.7723950061003367\nEpoch 102, Validation Loss: 0.5756409169832866\nEpoch 103, Validation Loss: 0.6405006920496623\nEpoch 104, Validation Loss: 0.8937768388589223\nEpoch 105, Validation Loss: 0.9934318950970967\nEpoch 106, Validation Loss: 0.6351472439765931\nEpoch 107, Validation Loss: 0.8706226212978363\nEpoch 108, Validation Loss: 0.9449308564662934\nEpoch 109, Validation Loss: 0.7678078034718832\nEpoch 110, Validation Loss: 0.7602820278803507\nEpoch 111, Validation Loss: 0.5739098632335663\nEpoch 112, Validation Loss: 0.5699526147047679\nEpoch 113, Validation Loss: 0.5733331847985585\nEpoch 114, Validation Loss: 0.6447973349889119\nEpoch 115, Validation Loss: 0.7529698231220245\nEpoch 116, Validation Loss: 0.558735842148463\nEpoch 117, Validation Loss: 0.5642578283150991\nEpoch 118, Validation Loss: 1.455269044717153\nEpoch 119, Validation Loss: 0.8621883457501729\nEpoch 120, Validation Loss: 0.5964676431814829\nEpoch 121, Validation Loss: 0.7742120837370554\nEpoch 122, Validation Loss: 0.6177090651988983\nEpoch 123, Validation Loss: 1.0650455088615418\nEpoch 124, Validation Loss: 0.5614092540740967\nEpoch 125, Validation Loss: 0.588132124821345\nEpoch 126, Validation Loss: 0.7715771829287211\nEpoch 127, Validation Loss: 0.5530469193458557\nEpoch 128, Validation Loss: 0.5649012717405955\nEpoch 129, Validation Loss: 0.5827989848454793\nEpoch 130, Validation Loss: 0.6958726293245951\nEpoch 131, Validation Loss: 0.7819294672807058\nEpoch 132, Validation Loss: 0.6464774702390035\nEpoch 133, Validation Loss: 0.582457245985667\nEpoch 134, Validation Loss: 0.6026719957987468\nEpoch 135, Validation Loss: 1.3670104500452678\nEpoch 136, Validation Loss: 0.743379960378011\nEpoch 137, Validation Loss: 0.6289263663291931\nEpoch 138, Validation Loss: 0.62485054119428\nEpoch 139, Validation Loss: 0.694482901096344\nEpoch 140, Validation Loss: 1.041754361152649\nEpoch 141, Validation Loss: 0.5930829635461171\nEpoch 142, Validation Loss: 1.3197928269704182\nEpoch 143, Validation Loss: 0.5504944279988607\nEpoch 144, Validation Loss: 0.5893656711578369\nEpoch 145, Validation Loss: 0.5950265181859334\nEpoch 146, Validation Loss: 0.5585966369311015\nEpoch 147, Validation Loss: 0.6485315669377645\nEpoch 148, Validation Loss: 0.5633097007274628\nEpoch 149, Validation Loss: 0.7317701876958211\nEpoch 150, Validation Loss: 0.5806725960572561\nEpoch 151, Validation Loss: 0.5649325398604075\nEpoch 152, Validation Loss: 0.6350592588583628\nEpoch 153, Validation Loss: 0.6625881887276968\nEpoch 154, Validation Loss: 0.6473067506949107\nEpoch 155, Validation Loss: 0.5532230010032654\nEpoch 156, Validation Loss: 0.8003511641025544\nEpoch 157, Validation Loss: 0.6862936018308003\nEpoch 158, Validation Loss: 0.6092108358542124\nEpoch 159, Validation Loss: 0.7425936008294424\nEpoch 160, Validation Loss: 0.5595584204991658\nEpoch 161, Validation Loss: 0.7567382136980693\nEpoch 162, Validation Loss: 0.834105402469635\nEpoch 163, Validation Loss: 0.6053402327696482\nEpoch 164, Validation Loss: 0.6469211304187774\nEpoch 165, Validation Loss: 0.5826098052660624\nEpoch 166, Validation Loss: 0.8398329601287842\nEpoch 167, Validation Loss: 0.5679594297409057\nEpoch 168, Validation Loss: 0.5733145645459493\nEpoch 169, Validation Loss: 0.6542553727626801\nEpoch 170, Validation Loss: 0.5337698935667674\nEpoch 171, Validation Loss: 0.5470642703374227\nEpoch 172, Validation Loss: 0.5192422796090443\nEpoch 173, Validation Loss: 0.6795367561181387\nEpoch 174, Validation Loss: 0.6497462856769561\nEpoch 175, Validation Loss: 0.5297977268695832\nEpoch 176, Validation Loss: 0.5709606607755026\nEpoch 177, Validation Loss: 0.6949525519212087\nEpoch 178, Validation Loss: 0.5286711623668671\nEpoch 179, Validation Loss: 0.6536160888671875\nEpoch 180, Validation Loss: 0.5278183929125468\nEpoch 181, Validation Loss: 0.5557343832651774\nEpoch 182, Validation Loss: 0.807777099609375\nEpoch 183, Validation Loss: 0.6667702960968017\nEpoch 184, Validation Loss: 0.6050888837178549\nEpoch 185, Validation Loss: 0.5728063935438792\nEpoch 186, Validation Loss: 0.5332977422078451\nEpoch 187, Validation Loss: 0.617663589000702\nEpoch 188, Validation Loss: 0.7714280378818512\nEpoch 189, Validation Loss: 0.6875048222541809\nEpoch 190, Validation Loss: 0.6329118038813273\nEpoch 191, Validation Loss: 0.8796737581094106\nEpoch 192, Validation Loss: 0.5382230388323466\nEpoch 193, Validation Loss: 0.5211064523855845\nEpoch 194, Validation Loss: 0.5284110410213471\nEpoch 195, Validation Loss: 0.6239374126593272\nEpoch 196, Validation Loss: 0.5690292719999949\nEpoch 197, Validation Loss: 0.5503486183484395\nEpoch 198, Validation Loss: 0.5228367435137431\nEpoch 199, Validation Loss: 0.5441923775672912\nEpoch 200, Validation Loss: 0.5077955025831858\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict on new data\nnew_smiles = ['C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy]', \n              'C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy]', \n              'C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ncnc3c2ncn3CC(C)O)n1)C(=O)N[Dy]', \n              'C#CCCC[C@H](Nc1nc(NCc2ccncc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy]', \n              'C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2cc(C(F)(F)F)ccn2)n1)C(=O)N[Dy]']\nnew_proteins = ['BRD4', 'sEH', 'BRD4', 'HSA', 'HSA']\nnew_protein_df = pd.DataFrame(new_proteins, columns=['protein_name'])\nnew_protein_encoded = encoder.transform(new_protein_df)\nnew_graph_data_list = []\n\nfor smiles, protein_encoding in zip(new_smiles, new_protein_encoded):\n    try:\n        graph = smiles_to_graph(smiles, protein_encoding)\n        if graph is not None:\n            new_graph_data_list.append(graph)\n    except Exception as e:\n        print(f\"Error processing SMILES '{smiles}': {e}\")\n\nnew_loader = DataLoader(new_graph_data_list, batch_size=1, shuffle=False)\n\npredictions = []\nwith torch.no_grad():\n    for data in new_loader:\n        logits = model(data)\n        print(f\"Logits: {logits}\")  # Debugging print\n        prediction = torch.sigmoid(logits).item()\n        predictions.append(prediction)\n\n# Print the predictions\nfor smiles, protein, pred in zip(new_smiles, new_proteins, predictions):\n    print(f'SMILES: {smiles}, Protein: {protein}, Predicted Binding Affinity: {pred}')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T11:30:46.112222Z","iopub.execute_input":"2024-06-09T11:30:46.112786Z","iopub.status.idle":"2024-06-09T11:30:46.179257Z","shell.execute_reply.started":"2024-06-09T11:30:46.112740Z","shell.execute_reply":"2024-06-09T11:30:46.178035Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Logits: tensor([[739.4473]])\nLogits: tensor([[746.6923]])\nLogits: tensor([[727.1858]])\nLogits: tensor([[750.7463]])\nLogits: tensor([[758.8871]])\nSMILES: C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy], Protein: BRD4, Predicted Binding Affinity: 1.0\nSMILES: C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy], Protein: sEH, Predicted Binding Affinity: 1.0\nSMILES: C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2ncnc3c2ncn3CC(C)O)n1)C(=O)N[Dy], Protein: BRD4, Predicted Binding Affinity: 1.0\nSMILES: C#CCCC[C@H](Nc1nc(NCc2ccncc2)nc(Nc2ccc(C=C)cc2)n1)C(=O)N[Dy], Protein: HSA, Predicted Binding Affinity: 1.0\nSMILES: C#CCCC[C@H](Nc1nc(Nc2ccc(C=C)cc2)nc(Nc2cc(C(F)(F)F)ccn2)n1)C(=O)N[Dy], Protein: HSA, Predicted Binding Affinity: 1.0\n","output_type":"stream"}]}]}